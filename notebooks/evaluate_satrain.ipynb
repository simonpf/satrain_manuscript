{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56b823a7-27da-4978-906c-5b859d3e7720",
   "metadata": {},
   "source": [
    "# Evaluate SatRain retrievals\n",
    "\n",
    "This notebook evaluates SatRain ML retrievals across all testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1235feb9-7b22-427f-97ab-d7e1f23d7eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb576081-3ec6-43dc-be50-d691fc302a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_retrieve import load_model\n",
    "model_gmi = load_model(\"/home/simon/src/ipwgml/models/satrain/gmi/ipwgml_gmi.pt\")\n",
    "model_geo = load_model(\"/home/simon/src/ipwgml/models/satrain/geo/checkpoints/ipwgml_geo-v3.ckpt\")\n",
    "model_geo_ir = load_model(\"/home/simon/src/ipwgml/models/satrain/geo_ir/ipwgml_geo_ir.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4d52ad8-9c5c-452d-875b-728194d43eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Dict\n",
    "import torch\n",
    "from torch import nn\n",
    "import xarray as xr\n",
    "\n",
    "from satrain.input import calculate_input_features\n",
    "\n",
    "class PytorchRetrieval:\n",
    "    \"\"\"\n",
    "    This class provides a generic retrieval callback function for PyTorch-based\n",
    "    retrievals.\n",
    "\n",
    "    The PytorchRetrieval wraps around a torch.nn.Module and extracts the input\n",
    "    data from the xarray.Dataset provided by the ipwgml.evaluation.Evaluator\n",
    "    and feeds it into the module. It then transform the output back from\n",
    "    PyTorch tensors to an xarray.Dataset containing the retrieval results.\n",
    "\n",
    "    The PytorchRetrieval class expects the module to return a dict containing\n",
    "    the keys 'surface_precip', 'probability_of_precip', and\n",
    "    'probability_of_heavy_precip'.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            model: nn.Module,\n",
    "            retrieval_input: List[str | Dict[str, Any]],\n",
    "            precip_threshold: float = 0.5,\n",
    "            heavy_precip_threshold: float = 0.5,\n",
    "            stack: bool = False,\n",
    "            logits: bool = True,\n",
    "            device: torch.device = torch.device(\"cpu\"),\n",
    "            dtype: torch.dtype = torch.float32,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model: A torch.nn.Module implementing the retrieval.\n",
    "            retrieval_input: A list defining the retrieval input.\n",
    "            precip_threshold: The probability threshold to apply to\n",
    "                transform the 'probability_of_precip' to a 'precip_flag'\n",
    "                output.\n",
    "            heavy_precip_threshold: Same as 'precip_threshold' but for\n",
    "                heavy precip flag output.\n",
    "            stack: Whether or not the model expects the input data to\n",
    "                be stacked ('True') or as dictionary.\n",
    "            logits: Whether the model returns logits instead of probabilities.\n",
    "            device: A torch.device defining the device on which to perform\n",
    "                inference.\n",
    "            dtype: The dtype to which to convert the retrieval input.\n",
    "        \"\"\"\n",
    "        self.model = model.to(device=device).eval()\n",
    "        self.features = calculate_input_features(retrieval_input, stack=False)\n",
    "        self.precip_threshold = precip_threshold\n",
    "        self.heavy_precip_threshold = heavy_precip_threshold\n",
    "        self.stack = stack\n",
    "        self.logits = logits\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def __call__(self, input_data: xr.Dataset) -> xr.Dataset:\n",
    "        \"\"\"\n",
    "        Run retrieval on input data.\n",
    "        \"\"\"\n",
    "        feature_dim = 0\n",
    "        if \"scan\" in input_data.dims:\n",
    "            spatial_dims = (\"scan\", \"pixel\")\n",
    "        elif \"latitude\" in input_data.dims:\n",
    "            spatial_dims = (\"latitude\", \"longitude\")\n",
    "        else:\n",
    "            spatial_dims = ()\n",
    "\n",
    "        if \"batch\" in input_data.dims:\n",
    "            dims = (\"batch\",) + spatial_dims\n",
    "            feature_dim += 1\n",
    "        else:\n",
    "            dims = spatial_dims\n",
    "\n",
    "\n",
    "        features = self.features\n",
    "        inpt = {}\n",
    "        for name in features:\n",
    "            inpt_data = torch.tensor(input_data[name].data).to(self.device, self.dtype)\n",
    "            if len(dims) == 1:\n",
    "                inpt_data = inpt_data.transpose(0, 1)\n",
    "            inpt[name] = inpt_data\n",
    "\n",
    "        if self.stack:\n",
    "            inpt = torch.cat(list(inpt.values()), dim=feature_dim)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = self.model(inpt)\n",
    "            surface_precip = pred[\"surface_precip\"].expected_value().float().cpu().numpy()\n",
    "            #pop = pred[\"precip_mask\"].probability().float().cpu().numpy()\n",
    "            #precip_mask = 0.5 < pop \n",
    "            #pop_heavy = pred[\"heavy_precip_mask\"].probability().float().cpu().numpy()\n",
    "            #heavy_precip_mask = 0.5 < pop_heavy\n",
    "            \n",
    "            results = xr.Dataset()\n",
    "            results[\"surface_precip\"] = (dims, surface_precip[:, 0])\n",
    "            #results[\"probability_of_precip\"] = (dims, pop[:, 0])\n",
    "            #results[\"precip_flag\"] = (dims, precip_mask[:, 0])\n",
    "            #results[\"probability_of_heavy_precip\"] = (dims, pop_heavy[:, 0])\n",
    "            #results[\"heavy_precip_flag\"] = (dims, heavy_precip_mask[:, 0])\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52509f9a-ab4f-4a50-9c69-2919f560eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "gmi_retrieval = PytorchRetrieval(\n",
    "    model_gmi,\n",
    "    retrieval_input=[\"gmi\"],\n",
    "    device=torch.device(\"cuda:1\"),\n",
    "    dtype=torch.float32 \n",
    ")\n",
    "geo_retrieval = PytorchRetrieval(\n",
    "    model_geo,\n",
    "    retrieval_input=[\"geo\"],\n",
    "    device=torch.device(\"cuda:1\"),\n",
    "    dtype=torch.float32 \n",
    ")\n",
    "geo_ir_retrieval = PytorchRetrieval(\n",
    "    model_geo_ir,\n",
    "    retrieval_input=[\"geo_ir\"],\n",
    "    device=torch.device(\"cuda:1\"),\n",
    "    dtype=torch.float32 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02dd0c7-55fd-4e49-9235-ac49b400feb0",
   "metadata": {},
   "source": [
    "## CONUS and Korea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bfcf12-e9b6-405c-b22e-1a375e50a6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9b165259ad47d387527d1ca3d0f5e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from satrain.evaluation import Evaluator\n",
    "from satrain.target import TargetConfig\n",
    "GOES_CHANNELS = [1, 2, 4, 6, 7, 9, 10, 11, 14, 15]\n",
    "\n",
    "retrievals = {\n",
    "    \"gmi\": gmi_retrieval,\n",
    "    \"geo_retrieval\": geo_retrieval,\n",
    "    \"geo_ir_retrieval\": geo_ir_retrieval\n",
    "}\n",
    "inputs = {\n",
    "    \"gmi\": {\"name\": \"gmi\", \"normalize\": \"minmax\", \"nan\": -2.0},\n",
    "    \"geo_retrieval\": {\"name\": \"geo\", \"normalize\": \"minmax\", \"nan\": -2.0, \"channels\": GOES_CHANNELS},\n",
    "    \"geo_ir_retrieval\": {\"name\": \"geo_ir\", \"normalize\": \"minmax\", \"nan\": -2.0},\n",
    "}\n",
    "\n",
    "for domain in [\"conus\", \"korea\"]:\n",
    "    for retrieval in retrievals:\n",
    "        evaluator = Evaluator(\n",
    "            domain=domain,\n",
    "            base_sensor=\"gmi\",\n",
    "            geometry=\"gridded\",\n",
    "            retrieval_input=[inputs[retrieval]]\n",
    "        )\n",
    "        evaluator.evaluate(retrievals[retrieval], tile_size=256, batch_size=32)\n",
    "        results = evaluator.get_results()\n",
    "        results.to_netcdf(f'results_{retrieval}_{domain}.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce048e1-0d63-44c3-b05d-81f156d09d26",
   "metadata": {},
   "source": [
    "## Austria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57d96b0-faed-45fe-b17c-bc45adb775cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from satrain.evaluation import Evaluator\n",
    "from satrain.target import TargetConfig\n",
    "SEVIRI_CHANNELS = [1, 2, 3, 4, 5, 6, 7, 8, 10, 11]\n",
    "\n",
    "retrievals = {\n",
    "    \"gmi\": gmi_retrieval,\n",
    "    \"geo_retrieval\": geo_retrieval\n",
    "    \"geo_ir_retrieval\": geo_ir_retrieval\n",
    "}\n",
    "inputs = {\n",
    "    \"gmi\": {\"name\": \"gmi\", \"normalize\": \"minmax\", \"nan\": -2.0},\n",
    "    \"geo_retrieval\": {\"name\": \"seviri\", \"normalize\": \"minmax\", \"nan\": -2.0, \"channels\": SEVIRI_CHANNELS, \"remap_obs\": True},\n",
    "    \"geo_ir_retrieval\": {\"name\": \"geo_ir\", \"normalize\": \"minmax\", \"nan\": -2.0},\n",
    "}\n",
    "\n",
    "for domain in [\"austria\"]:\n",
    "    for retrieval in retrievals:\n",
    "        evaluator = Evaluator(\n",
    "            domain=domain,\n",
    "            base_sensor=\"gmi\",\n",
    "            geometry=\"gridded\",\n",
    "            retrieval_input=[inputs[retrieval]]\n",
    "    )\n",
    "    evaluator.evaluate()\n",
    "    results = evaluator.get_results()\n",
    "    results.to_netcdf(f'results_{retrieval}_{domain}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7fdd3fa-7356-4e21-91c9-5e54139e0323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from satrain.input import Ancillary\n",
    "anc = Ancillary(variables=[\"total_precipitation\"])\n",
    "\n",
    "def retrieve_era5(input_data: xr.Dataset) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Retrieval callback function to load GPROF data corresponding to IPWGML SPR evaluation data.\n",
    "\n",
    "    Args:\n",
    "        input_data: An xarray.Dataset containing the retrieval input data.\n",
    "\n",
    "    Return:\n",
    "        An xarray.Dataset containing the retrieval results.\n",
    "    \"\"\"\n",
    "    lons = input_data.longitude.data\n",
    "    lats = input_data.latitude.data\n",
    "    tp = input_data.ancillary.data[:, 0]\n",
    "        \n",
    "    return xr.Dataset({\n",
    "        \"surface_precip\": ((\"batch\", \"latitude\", \"longitude\"), tp * 1e3),\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
